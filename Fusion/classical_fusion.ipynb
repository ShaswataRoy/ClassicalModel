{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4053c933-eaea-4cc8-b036-1033c4b9918c",
   "metadata": {},
   "source": [
    "# Fusion\n",
    "\n",
    "The following code is to be used on the numpy arrays derived from the 3D CNN and SGCNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "478dbd93-9730-445c-9259-786605ed2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "from scipy.stats import *\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ae74435-d2de-4630-8b4c-15c05b435777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epochs, model, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to save the trained model to disk.\n",
    "    \"\"\"\n",
    "    print(f\"Saving final model...\")\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, 'models/fusion.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71587bf1-59dd-46cd-8e9e-25c0ff7d6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, numpy_file,true_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        # self.feat1 = np.load(numpy_file1)\n",
    "        # self.feat2 = np.load(numpy_file2)\n",
    "        # self.feat = np.concatenate([self.feat1,self.feat2],axis=1)\n",
    "        self.feat = numpy_file\n",
    "        self.y = true_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.feat[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db1fdc95-9e1c-4b58-abf2-ac958bf83b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATOMFusionModel(nn.Module):\n",
    "    # Based on the ATOM Fusion Model\n",
    "    def __init__(self):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc11 = nn.Linear(10, 5) \n",
    "        self.fc12 = nn.Linear(6, 5) \n",
    "\n",
    "        # Non-linearity\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn1 = nn.BatchNorm1d(5)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.lrelu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(26, 10) \n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = x\n",
    "        feat1 = feat[:,:10]\n",
    "        feat2 = feat[:,10:]\n",
    "        # Linear function  # LINEAR\n",
    "        hidden1 = self.fc11(feat1)\n",
    "        hidden2 = self.fc12(feat2)\n",
    "        hidden1 = self.lrelu(self.bn1(self.drop(hidden1)))\n",
    "        hidden2 = self.lrelu(self.bn1(self.drop(hidden2)))\n",
    "        \n",
    "\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        concat = torch.cat((feat1, hidden1, feat2, hidden2), 1)\n",
    "        \n",
    "        hidden3 = self.fc2(concat)\n",
    "        hidden3 = self.bn2(self.relu(hidden3))\n",
    "        \n",
    "        hidden4 = self.fc3(hidden3)\n",
    "        \n",
    "        \n",
    "        out = hidden4\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550f875-b4a7-495d-a646-49fee7a737c4",
   "metadata": {},
   "source": [
    "Define the classical feedforward fusion network. Composed of a couple of feedforward layers followed by a ReLU activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb79bd32-8457-4f3c-b93d-68491a87f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = OrderedDict()\n",
    "\n",
    "num_layers = 4\n",
    "for i in range(num_layers):\n",
    "    od[str(i)] = nn.Linear(16, 16)\n",
    "\n",
    "od[str(num_layers)] = nn.Linear(16, 1)\n",
    "od[str(num_layers+1)] = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb987a98-ba4b-42af-a0fa-c4e865d89f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optim_param = [1, 0.002, 0.9, 0.999, 1e-08]\n",
    "model = nn.Sequential(\n",
    "    od\n",
    ")\n",
    "\n",
    "model = FeedforwardNeuralNetModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=optim_param[1],eps = optim_param[4])  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=optim_param[1], betas=(optim_param[2],optim_param[3]),eps = optim_param[4])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.99)\n",
    "\n",
    "num_epochs = 10000\n",
    "batch_size=50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e90db-6793-46da-9cd6-5bf2fafe19fc",
   "metadata": {},
   "source": [
    "Defining the training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a95cf22e-39e0-4126-924a-777980bede44",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_val = np.concatenate([np.load('refined_val_fc10.npy'),np.load('refined_val_fc6_new.npy')],axis=1)\n",
    "refined_train = np.concatenate([np.load('refined_train_fc10.npy'),np.load('refined_train_fc6_new.npy')],axis=1)\n",
    "general_train = np.concatenate([np.load('general_train_fc10.npy'),np.load('general_train_fc6.npy')],axis=1)\n",
    "general_val = np.concatenate([np.load('general_val_fc10.npy'),np.load('general_val_fc6.npy')],axis=1)\n",
    "core_test = np.concatenate([np.load('core_test_fc10.npy'),np.load('core_test_fc6.npy')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b7522be-ca70-4694-8606-e6b78e1e4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datasets = np.concatenate([general_train,general_val,refined_train,refined_val],axis=0)\n",
    "train_datasets = np.concatenate([refined_train,refined_val],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9dff6e05-e39f-4562-88b9-b16a0dcc05f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_train_pred = pd.read_csv('general_train_pred.csv')['label'].to_numpy().astype('float32')\n",
    "general_val_pred = pd.read_csv('general_val_pred.csv')['label'].to_numpy().astype('float32')\n",
    "refined_train_pred = pd.read_csv('refined_train_pred.csv')['label'].to_numpy().astype('float32')\n",
    "refined_val_pred = pd.read_csv('refined_val_pred.csv')['label'].to_numpy().astype('float32')\n",
    "core_test_pred = pd.read_csv('core_test_pred.csv')['label'].to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c677515a-77a8-4766-ac10-e7069b036e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred = np.concatenate([general_train_pred,general_val_pred,refined_train_pred,refined_val_pred])\n",
    "train_pred = np.concatenate([refined_train_pred,refined_val_pred])\n",
    "train_pred_normed = train_pred/np.max(abs(train_pred))\n",
    "core_test_pred_normed = core_test_pred/np.max(abs(core_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51263745-d341-4496-a5a9-b1430b121bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = FusionDataset(numpy_file = train_datasets,\n",
    "                    true_file = train_pred)\n",
    "test_dset = FusionDataset(numpy_file = core_test,\n",
    "                    true_file = core_test_pred)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dset, \n",
    "                                           batch_size=len(test_dset), \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "020df1fd-00cc-4a59-978b-6ae452c6a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000. Loss: 5.804025650024414\n",
      "Saving final model...\n",
      "Iteration: 2000. Loss: 2.2687880992889404\n",
      "Saving final model...\n",
      "Iteration: 3000. Loss: 1.17572820186615\n",
      "Saving final model...\n",
      "Iteration: 4000. Loss: 1.5951635837554932\n",
      "Iteration: 5000. Loss: 2.316443681716919\n",
      "Iteration: 6000. Loss: 0.6069284677505493\n",
      "Saving final model...\n",
      "Iteration: 7000. Loss: 1.1931092739105225\n",
      "Iteration: 8000. Loss: 1.3417868614196777\n",
      "Iteration: 9000. Loss: 1.0254104137420654\n",
      "Iteration: 10000. Loss: 1.6149123907089233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.525395990721731,\n",
       " 1.1795211,\n",
       " PearsonRResult(statistic=0.7443099824474084, pvalue=1.5273503934223836e-51),\n",
       " SpearmanrResult(correlation=0.7401033390114357, pvalue=1.0984716465843504e-50),\n",
       " 1.4953036)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter = 0\n",
    "num_epochs=100\n",
    "loss_min=100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (feat,labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Load images with gradient accumulation capabilities\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(feat).reshape(-1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        \n",
    "        #scheduler.step()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "\n",
    "        if iter % 1000 == 0:\n",
    "            print('Iteration: {}. Loss: {}'.format(iter, loss.item()))\n",
    "            if loss.item()<loss_min:\n",
    "                loss_min = loss.item()\n",
    "                save_model(epoch, model, optimizer, criterion)\n",
    "            loss_ar.append(loss.item())\n",
    "                \n",
    "# Load from Checkpoint\n",
    "checkpoint = torch.load('models/fusion.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Test the Model\n",
    "\n",
    "for i, (feat,labels) in enumerate(test_loader):\n",
    "    outputs = model(feat).detach().numpy()\n",
    "ytrue = labels\n",
    "ypred = outputs.reshape(-1)\n",
    "r2_score(ytrue,ypred),mean_absolute_error(ypred,ytrue),pearsonr(ypred,ytrue),spearmanr(ypred,ytrue),np.sqrt(mean_squared_error(ypred,ytrue))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sgcnn)",
   "language": "python",
   "name": "sgcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
